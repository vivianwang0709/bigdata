{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://toppqsvvpcgceh:8e560b0767dc6b30d5140589013a2baca8752165a642c8188459ca806176fa4c@ec2-54-243-252-91.compute-1.amazonaws.com:5432/da1ftjs8usjpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = engine.execute(\"SELECT table_schema,table_name FROM information_schema.tables ORDER BY table_schema,table_name;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema', 'administrable_role_authorizations')\n",
      "('information_schema', 'applicable_roles')\n",
      "('information_schema', 'attributes')\n",
      "('information_schema', 'character_sets')\n",
      "('information_schema', 'check_constraint_routine_usage')\n",
      "('information_schema', 'check_constraints')\n",
      "('information_schema', 'collation_character_set_applicability')\n",
      "('information_schema', 'collations')\n",
      "('information_schema', 'column_domain_usage')\n",
      "('information_schema', 'column_options')\n",
      "('information_schema', 'column_privileges')\n",
      "('information_schema', 'columns')\n",
      "('information_schema', 'column_udt_usage')\n",
      "('information_schema', 'constraint_column_usage')\n",
      "('information_schema', 'constraint_table_usage')\n",
      "('information_schema', 'data_type_privileges')\n",
      "('information_schema', 'domain_constraints')\n",
      "('information_schema', 'domains')\n",
      "('information_schema', 'domain_udt_usage')\n",
      "('information_schema', 'element_types')\n",
      "('information_schema', 'enabled_roles')\n",
      "('information_schema', 'foreign_data_wrapper_options')\n",
      "('information_schema', 'foreign_data_wrappers')\n",
      "('information_schema', 'foreign_server_options')\n",
      "('information_schema', 'foreign_servers')\n",
      "('information_schema', 'foreign_table_options')\n",
      "('information_schema', 'foreign_tables')\n",
      "('information_schema', 'information_schema_catalog_name')\n",
      "('information_schema', 'key_column_usage')\n",
      "('information_schema', 'parameters')\n",
      "('information_schema', 'referential_constraints')\n",
      "('information_schema', 'role_column_grants')\n",
      "('information_schema', 'role_routine_grants')\n",
      "('information_schema', 'role_table_grants')\n",
      "('information_schema', 'role_udt_grants')\n",
      "('information_schema', 'role_usage_grants')\n",
      "('information_schema', 'routine_privileges')\n",
      "('information_schema', 'routines')\n",
      "('information_schema', 'schemata')\n",
      "('information_schema', 'sequences')\n",
      "('information_schema', 'sql_features')\n",
      "('information_schema', 'sql_implementation_info')\n",
      "('information_schema', 'sql_languages')\n",
      "('information_schema', 'sql_packages')\n",
      "('information_schema', 'sql_sizing')\n",
      "('information_schema', 'sql_sizing_profiles')\n",
      "('information_schema', 'table_constraints')\n",
      "('information_schema', 'table_privileges')\n",
      "('information_schema', 'tables')\n",
      "('information_schema', 'triggered_update_columns')\n",
      "('information_schema', 'triggers')\n",
      "('information_schema', 'udt_privileges')\n",
      "('information_schema', 'usage_privileges')\n",
      "('information_schema', 'user_defined_types')\n",
      "('information_schema', 'user_mapping_options')\n",
      "('information_schema', 'user_mappings')\n",
      "('information_schema', 'view_column_usage')\n",
      "('information_schema', 'view_routine_usage')\n",
      "('information_schema', 'views')\n",
      "('information_schema', 'view_table_usage')\n",
      "('pg_catalog', 'pg_aggregate')\n",
      "('pg_catalog', 'pg_am')\n",
      "('pg_catalog', 'pg_amop')\n",
      "('pg_catalog', 'pg_amproc')\n",
      "('pg_catalog', 'pg_attrdef')\n",
      "('pg_catalog', 'pg_attribute')\n",
      "('pg_catalog', 'pg_auth_members')\n",
      "('pg_catalog', 'pg_available_extensions')\n",
      "('pg_catalog', 'pg_available_extension_versions')\n",
      "('pg_catalog', 'pg_cast')\n",
      "('pg_catalog', 'pg_class')\n",
      "('pg_catalog', 'pg_collation')\n",
      "('pg_catalog', 'pg_constraint')\n",
      "('pg_catalog', 'pg_conversion')\n",
      "('pg_catalog', 'pg_cursors')\n",
      "('pg_catalog', 'pg_database')\n",
      "('pg_catalog', 'pg_db_role_setting')\n",
      "('pg_catalog', 'pg_default_acl')\n",
      "('pg_catalog', 'pg_depend')\n",
      "('pg_catalog', 'pg_description')\n",
      "('pg_catalog', 'pg_enum')\n",
      "('pg_catalog', 'pg_event_trigger')\n",
      "('pg_catalog', 'pg_extension')\n",
      "('pg_catalog', 'pg_foreign_data_wrapper')\n",
      "('pg_catalog', 'pg_foreign_server')\n",
      "('pg_catalog', 'pg_foreign_table')\n",
      "('pg_catalog', 'pg_group')\n",
      "('pg_catalog', 'pg_index')\n",
      "('pg_catalog', 'pg_indexes')\n",
      "('pg_catalog', 'pg_inherits')\n",
      "('pg_catalog', 'pg_init_privs')\n",
      "('pg_catalog', 'pg_language')\n",
      "('pg_catalog', 'pg_largeobject_metadata')\n",
      "('pg_catalog', 'pg_locks')\n",
      "('pg_catalog', 'pg_matviews')\n",
      "('pg_catalog', 'pg_namespace')\n",
      "('pg_catalog', 'pg_opclass')\n",
      "('pg_catalog', 'pg_operator')\n",
      "('pg_catalog', 'pg_opfamily')\n",
      "('pg_catalog', 'pg_pltemplate')\n",
      "('pg_catalog', 'pg_policies')\n",
      "('pg_catalog', 'pg_policy')\n",
      "('pg_catalog', 'pg_prepared_statements')\n",
      "('pg_catalog', 'pg_prepared_xacts')\n",
      "('pg_catalog', 'pg_proc')\n",
      "('pg_catalog', 'pg_range')\n",
      "('pg_catalog', 'pg_replication_origin')\n",
      "('pg_catalog', 'pg_replication_slots')\n",
      "('pg_catalog', 'pg_rewrite')\n",
      "('pg_catalog', 'pg_roles')\n",
      "('pg_catalog', 'pg_rules')\n",
      "('pg_catalog', 'pg_seclabel')\n",
      "('pg_catalog', 'pg_seclabels')\n",
      "('pg_catalog', 'pg_settings')\n",
      "('pg_catalog', 'pg_shdepend')\n",
      "('pg_catalog', 'pg_shdescription')\n",
      "('pg_catalog', 'pg_shseclabel')\n",
      "('pg_catalog', 'pg_stat_activity')\n",
      "('pg_catalog', 'pg_stat_all_indexes')\n",
      "('pg_catalog', 'pg_stat_all_tables')\n",
      "('pg_catalog', 'pg_stat_archiver')\n",
      "('pg_catalog', 'pg_stat_bgwriter')\n",
      "('pg_catalog', 'pg_stat_database')\n",
      "('pg_catalog', 'pg_stat_database_conflicts')\n",
      "('pg_catalog', 'pg_statio_all_indexes')\n",
      "('pg_catalog', 'pg_statio_all_sequences')\n",
      "('pg_catalog', 'pg_statio_all_tables')\n",
      "('pg_catalog', 'pg_statio_sys_indexes')\n",
      "('pg_catalog', 'pg_statio_sys_sequences')\n",
      "('pg_catalog', 'pg_statio_sys_tables')\n",
      "('pg_catalog', 'pg_statio_user_indexes')\n",
      "('pg_catalog', 'pg_statio_user_sequences')\n",
      "('pg_catalog', 'pg_statio_user_tables')\n",
      "('pg_catalog', 'pg_stat_progress_vacuum')\n",
      "('pg_catalog', 'pg_stat_replication')\n",
      "('pg_catalog', 'pg_stats')\n",
      "('pg_catalog', 'pg_stat_ssl')\n",
      "('pg_catalog', 'pg_stat_sys_indexes')\n",
      "('pg_catalog', 'pg_stat_sys_tables')\n",
      "('pg_catalog', 'pg_stat_user_functions')\n",
      "('pg_catalog', 'pg_stat_user_indexes')\n",
      "('pg_catalog', 'pg_stat_user_tables')\n",
      "('pg_catalog', 'pg_stat_wal_receiver')\n",
      "('pg_catalog', 'pg_stat_xact_all_tables')\n",
      "('pg_catalog', 'pg_stat_xact_sys_tables')\n",
      "('pg_catalog', 'pg_stat_xact_user_functions')\n",
      "('pg_catalog', 'pg_stat_xact_user_tables')\n",
      "('pg_catalog', 'pg_tables')\n",
      "('pg_catalog', 'pg_tablespace')\n",
      "('pg_catalog', 'pg_timezone_abbrevs')\n",
      "('pg_catalog', 'pg_timezone_names')\n",
      "('pg_catalog', 'pg_transform')\n",
      "('pg_catalog', 'pg_trigger')\n",
      "('pg_catalog', 'pg_ts_config')\n",
      "('pg_catalog', 'pg_ts_config_map')\n",
      "('pg_catalog', 'pg_ts_dict')\n",
      "('pg_catalog', 'pg_ts_parser')\n",
      "('pg_catalog', 'pg_ts_template')\n",
      "('pg_catalog', 'pg_type')\n",
      "('pg_catalog', 'pg_user')\n",
      "('pg_catalog', 'pg_user_mappings')\n",
      "('pg_catalog', 'pg_views')\n",
      "('public', 'alembic_version')\n",
      "('public', 'article')\n",
      "('public', 'users')\n"
     ]
    }
   ],
   "source": [
    "for a in result:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '作為大數據從業人員，如何寫好一份可堪入目的簡歷? | BIN 大數據', 'vivian', '<article class=\"article-content\"><p><img alt=\"大數據\" class=\"36img\" src=\"../static/pic/code/1_1.jpg\"/></p><p>文 | blogchong</p><p>近期部門在做人員招聘，所以一直在堅持看簡歷，包括也面了部分相關崗位的候選者，有些感觸還是蠻大的。</p><p>最想吐槽的一個點就是，混了好幾年工作了，真的該好好學學怎麼寫一份讓人看得爽點的簡歷，不讓自己難看，也不讓面試官蛋疼。</p><p>恰巧數據蟲巢讀者私密群中也有童鞋需要去找工作了，而且年後恰是換坑好時節，趁此機會，為這個話題開個單篇吧。</p><p>我先不說專門如何去構造一份簡歷，單純的講述一下作為一個大數據相關崗位的面試官，我是如何去翻閱簡歷的。</p><p><span style=\"color: #ff6600;\"><strong>通常，候選人簡歷上寫的東西，我或多或少都會問的，當然前提是跟大數據相關項目以及相關技能點。</strong></span></p><p><strong>那這意味著什麼呢?</strong></p><p>意味著你寫上去的東西都將會面臨考驗，而如果你面試的是大數據相關的崗位，與大數據相關度不大的相關經歷，就不要多費筆墨了。</p><p>因為這些額外的項目經歷並不會為你額外加分，只會影響面試官查看簡歷的心情，一筆帶過就好了。</p><p>如上所說，既然簡歷上的相關信息面試官都會關註，那麼，什麼東西該往上面放呢?</p><p>最基本的要求就是，你能hold住面試官盤問的東西，每一行信息你都需要確認，這些東西我都很熟悉，面試官變著法兒問，我也能變著法兒回答。</p><p>所以，簡歷上的東西並不是多多益善，而是在於在於精，並且在於經得住考驗，這是簡曆書寫的第一要點。</p><p><span style=\"color: #ff6600;\"><strong>第二，整體信息如何去佈局呢?</strong></span></p><p>我一般看大數據相關的簡歷，這幾部分的信息肯定是會關註的：</p><p>1 畢業學校以及學歷，對應的專業或者研究方向。</p><p>2 工作年限。</p><p>3 工作經歷，即跳槽史。</p><p>4 項目經歷。</p><p>5 對於自己擅長東西的總結彙總。</p><p>我一般不太關註的東西：</p><p>1 自我評價部分，尤其是那種自我感覺良好的書寫，更加負分。</p><p>2 學校獲獎或者各種發表論文的部分，講真，國內論文的水有多深，我真的挺清楚的，當然，你要是能發表個國際公認論文水準的期刊，分分鐘給你加分。</p><p>3 其他諸如什麼籍貫啊、居住地亂七八糟的基礎信息，真的不關心(基礎信息我只關註男女，學歷相關的信息，工作年份)，也沒必要過多寫。</p><p><strong>欣賞額外的一些信息：</strong></p><p>1 除了常規以外的相關優點，當然，前提是你這個優點對應應聘崗位有特別明顯的作用，不然就是顯擺，負分滾粗。</p><p>這點可以舉個簡單例子，如果招聘的爬蟲工程師，應聘者說自己平時沒事就逛逛微博、知乎，當然是用程序，那些地方就跟自己後花園似的，從那些地方獲取的數據一坨又一坨，就只差拿出來賣了。</p><p>這種自己愛折騰的爬蟲工程師，單憑這條技能，分分鐘可以給他的整體評分上揚個30%。</p><p>針對上面這些情況，哪些該詳細寫，哪些該屏蔽應該差不多了吧。</p><p><strong>當然，對於要寫的東西，面試時其側重點也是不同的。</strong></p><p>比如，對於我現在要招的數據挖掘工程師，我會著重關註其畢業學校以及最高學歷，並且這項將會占據整體面試評分中不低的評分。</p><p><strong>因為，作為以算法為核心基礎的數據挖掘工程師，沒有一個好的學校、學歷，以及對口的研究方向做支撐，是很難在理論這塊站得住腳跟的。</strong></p><p>而對於普通的大數據開發工程師或者爬蟲工程師，這塊要求相對就可以放低了，因為大學學的東西對後面所掌握的技能知識影響並沒有想象中大。</p><p>其次，對於公司經歷相對較好的童鞋，公司背景也是小小的加分項，畢竟好公司還是有一定的背書能力的。</p><p>那麼，對於那些公司經歷相對不是那麼耀眼的童鞋，重心需要適當放在項目經驗上，試圖在這塊彌補公司經歷的不足。</p><p><strong>書寫項目經歷時，註意幾個點：</strong></p><p>1 對口項目細寫，把相關的技能都很好的展現出來，當然，前提是不管是項目也好，涉及的技能也好，需要經得起盤問。</p><p>2 儘量的平實的描繪自己在其中的作用，不需要你一個人逆天，但需要你有體現價值的地方。</p><p>3 項目經歷不需要事事都寫上，輕重緩急分清，對口的、參與程度高的適當體現，不重要的，跟你應聘崗位沒啥卵關係的，一筆帶過，這樣會讓面試官更容易找到重點，換言之，也可以把面試官的註意力圈定在你所擅長的地方，所以，別犯傻。</p><p>4 項目經歷一定要有以下幾部分內容，項目目的、項目流程、時間周期、人員分工、自己的核心重點，所涉及的技術、架構、相關技能，能夠把這些邏輯理清也是個技術活兒。</p><p>對於項目這塊，面試官最喜歡的是找漏子，包括我也是，因為我想看到項目中的一些不足之處，然後想看看你到底會如何處理。</p><p>所以，在準備項目經歷時，對於淌過的坑一定要梳理梳理，此外就是自己查找出相關的漏子，試圖去舉一反三。</p><p>沒有哪個面試官會喜歡不動腦子的候選者，只對做過的東西熟悉，對沒有做過的東西連想法都沒有的人是可怕的。</p><p>除了項目經驗這塊，對於自己所擅長的東西，一定要做一個總結彙總，這是對自己的肯定，也是對面試的尊重，總不能讓面試官去猜你擅長哪些技能吧。</p><p>我一般除了重點會照顧項目經歷之外，對於彙總處的技能點，也會挨個盤查，這種盤查是脫離項目之外的，單純的底層知識積累的考核。</p><p>這塊的彙總同樣的，沒必要把你十八般武藝都放上去，記得放在前頭的一定是對口的、並且是你所熟悉的。</p><p>1 我招大數據相關崗位的，你把java相關技能放在前頭的還能忍，把什麼前端技能寫一大坨，還放第一排的，直接負分滾粗。</p><p>2 別是個技能都寫上精通，你需要確認你是否真的精通，別寫著精通的，我問一個你不懂一個，直接負分滾粗，但你要寫著“瞭解”級別的，我會認為你不懂很正常。</p><p>所以整個簡歷的書寫，總結起來其實很簡單，別一股腦兒平鋪陳述，重要的是對口，分得清主次，最後，經得住考驗。</p><p><strong>繞幾句舌：</strong></p><p>1 你不懂沒關係，沒有人什麼都懂，懂該懂的東西就夠了。</p><p>2 但是，如果你說你懂，結果問你你又不懂，那就尷尬了。</p><p>3 如果你真的懂，你要告訴我你懂，你不告訴我你懂，難道讓我去猜，這就尷尬了。</p><p>此外，不建議簡歷造假，在老司機面前很容易出漏子的，出了漏子更是大寫的尷尬。</p><p>當然，如果說你能hold主，你來你上，把我搞定了我就認為它是真的了(假能圓成這樣，說明還是有本事的 哈哈，招了也不虧)!</p><p><strong>最最後說一點，簡歷一定不要弄的太花哨，對的，咱這題圖可不是讓你學習的，反面例子。</strong></p><p>搞技術的把該說的說清楚完事，別凈扯些沒用的，這點特別適合剛畢業的應屆生朋友。</p><p>黃崇遠，花名博客蟲，“數據蟲巢”個人品牌所有者（官網www.mite8.com、公眾號、簡書、博客），近6年的大數據行業經驗，線下組織過大數據技術沙龍，線上授過大數據課，目前於深圳任職於一B輪創業公司大數據主管。</p><p>End.</p><p>\\xa0</p><p>轉載請註明來自36大數據（36dsj.com)：<a href=\"http://www.36dsj.com\">36大數據</a> » <a href=\"http://www.36dsj.com/archives/77285\">作為大數據從業人員，如何寫好一份可堪入目的簡歷?</a></p> </article>', '近期部門在做人員招聘，所以一直在堅持看簡歷，包括也面了部分相關崗位的候選者，有些感觸還是蠻大的。', '2017-04-27', 'code', None, None, 'http://www.36dsj.com/archives/77285', 1, None)\n",
      "(2, '谷歌微軟等科技巨頭數據科學面試107道真題：你能答出多少？ | BIN 大數據', 'vivian', '<article class=\"article-content\"><p><a href=\"http://www.36dsj.com/wp-content/uploads/2017/03/3-10.jpg\"><img alt=\"數據科學家\" class=\"36img\" src=\"../static/pic/code/2_1.jpg\"/></a></p><p>來自 Glassdoor 的最新數據可以告訴我們各大科技公司最近在招聘面試時最喜歡向候選人提什麼問題。首先有一個令人惋惜的結論：根據統計，幾乎所有的公司都有著自己的不同風格。由於 Glassdoor 允許匿名提交內容，很多樂於分享的應聘者向大家提供了 Facebook、谷歌、微軟等大公司的面試題。我們把其中的一部分列出以供大家參考。</p><h2><strong>通用問題</strong></h2><p><strong>蘋果</strong></p><p>1. 如果你有幾百萬用戶，每個用戶都會發生數百筆交易，這些交易存在於數十種產品中。你該如何把這些用戶細分成有意義的幾類？</p><p>微軟</p><p>1. 描述一個你曾經參與的項目，以及它的優點。</p><p>2. 如何處理具有高基數（high-cardinality）的類屬特征？</p><p>3. 如果想要給 Twitter feed 寫 summarize，你要怎麼辦？</p><p>4. 在應用機器學習算法之前糾正和清理數據的步驟是什麼？</p><p>5. 如何測量數據點之間的距離？</p><p>6. 請定義一下方差。</p><p>7. 請描述箱形圖（box plot）和直方圖（histogram）之間的差異，以及它們的用例。</p><p><strong>Twitter</strong></p><p>1. 你會使用什麼功能來為用戶構建推薦算法？</p><p><strong>Uber</strong></p><p>1. 選擇任何一個你真正喜歡的產品或應用程序，並描述如何改善它。</p><p>2. 如何在分佈中發現異常？</p><p>3. 如何檢查分佈中的某個趨勢是否是由於異常產生的？</p><p>4. 如何估算 Uber 對交通和駕駛環境造成的影響？</p><p>5. 你會考慮用什麼指標來跟蹤 Uber 付費廣告策略在吸引新用戶上是否有效？然後，你想用什麼辦法估算出理想的客戶購置成本？</p><p><strong>領英（LinkedIn）</strong></p><p>1.（對大數據工程師）請解釋 REST 是什麼。</p><h2><strong>機器學習問題</strong></h2><p><strong>谷歌</strong></p><p>1. 為什麼要使用特征選擇（feature selection）？</p><p>2. 如果兩個預測變量高度相關，它們對邏輯回歸繫數的影響是什麼？繫數的置信區間是什麼？</p><p>3. 高斯混合模型（Gaussian Mixture Model）和 K-Means 之間有什麼區別？</p><p>4. 在 K-Means 中如何拾取 k？</p><p>5. 你如何知道高斯混合模型是不是適用的？</p><p>6. 假設聚類模型的標簽是已知的，你如何評估模型的性能？</p><p><strong>微軟</strong></p><p>1. 你有哪些引以為豪的機器學習項目？</p><p>2. 隨便找一個機器學習算法，然後描述它。</p><p>3. 請解釋 Gradient Boosting 是如何工作的。</p><p>4.（對數據挖掘工程師）請解釋決策樹模型。</p><p>5.（對數據挖掘工程師）什麼是神經網絡？</p><p>6. 請解釋偏差方差權衡（Bias-Variance Tradeoff）。</p><p>7. 如何處理不平衡二進制分類？</p><p>8.L1 和 L2 正則化之間有什麼區別？</p><p><strong>Uber</strong></p><p>1. 你會通過哪種特征來預測 Uber 司機是否會接受訂單請求？你會使用哪種監督學習算法來解決這個問題，如何比較算法的結果？</p><p><strong>領英</strong></p><p>1. 點出及描述三種不同的內核函數，在哪些情況下使用哪種？</p><p>2. 隨意解釋機器學習里的一種方法。</p><p>3. 如何應付稀疏數據？</p><p><strong>IBM</strong></p><p>1. 如何防止過擬合（overfitting）？</p><p>2. 如何處理數據中的離群值？</p><p>3. 如何評估邏輯回歸與簡單線性回歸模型預測的性能？</p><p>4. 監督學習和無監督學習有什麼區別？</p><p>5. 什麼是交叉驗證（cross-validation），為什麼要使用它？</p><p>6. 用於評估預測模型的矩陣的名稱是什麼？</p><p>7. 邏輯回歸繫數和勝算比（Odds Ratio）之間存在什麼關係？</p><p>8. 主成分分析（PCA）和線性和二次判別分析（LDA 和 QDA）之間的關係是什麼？</p><p>9. 如果你有一個因變量分類，又有一個連續自變量的混合分類，你將使用什麼算法，方法或工具進行分析？</p><p>10.（對行業分析師）邏輯與線性回歸有什麼區別？如何避免局部極小值？</p><p><strong>Salesforce</strong></p><p>1. 你會使用哪些數據和模型來測量損耗/流失？如何測試模型性能？</p><p>2. 假設我是一名非技術人員，請向我解釋一種機器學習算法。</p><p><strong>Capital One（一家美國銀行）</strong></p><p>1. 如何構建一個模型來預測信用卡詐騙？</p><p>2. 如何處理丟失或不良數據？</p><p>3. 如何從已存在的特征中導出新的特征？</p><p>4. 如果你試圖預測客戶的性別，但只有 100 個數據點，可能會出現什麼問題？</p><p>5. 在擁有兩年交易歷史的情況下，哪些特征可以用來預測信用風險？</p><p>6. 請設計一個用來下井字棋的人工智能程序。</p><p><strong>Zillow</strong></p><p>1. 請解釋過擬合，以及如何防止過擬合。</p><p>2. 為什麼 SVM 需要在支持向量之間最大化邊緣？</p><h2><strong>Hadoop</strong></h2><p><strong>Twitter</strong></p><p>1. 如何使用 Map/Reduce 將非常大的圖形分割成更小的塊，並根據數據的快速/動態變化並行計算它們的邊緣？</p><p>2.（對數據工程師）給定一個列表：123, 345234, 678345, 123…其中第一列是粉絲的 ID，第二列是被粉者的 ID。查找所有相互後續對（上面的示例中的對是 123，345）。當列表超出內存時，如何使用 Map / Reduce 來解決問題？</p><p><strong>Captial One</strong></p><p>1.（對數據工程師）什麼是 Hadoop 序列化（serialization）？</p><p>2. 解釋一個簡單的 Map / Reduce 問題。</p><h2><strong>Hive</strong></h2><p><strong>領英</strong></p><p>1.（對數據工程師）請編寫返回情感分數的 Hive UDF。例如，假如好=1，壞=-1，平均數=0，那麼對餐廳做評價時因為「食物好，服務差」，你的分數可能為 1 – 1 = 0</p><h2><strong>Spark</strong></h2><p><strong>Captial One</strong></p><p>1.（對數據工程師）用 Scala 語言，RDD 在 Spark 中是如何工作的？</p><h2><strong>統計和概率問題</strong></h2><p><strong>谷歌</strong></p><p>1. 假設我是一名非技術人員，請向我解釋一下交叉驗證（Cross-validation）。</p><p>2. 請描述一下非正態概率分佈，隨後告訴我們它該如何應用？</p><p><strong>微軟</strong></p><p>1.（對數據挖掘）請解釋異方差（heteroskedasticity）是什麼，以及如何解決它。</p><p><strong>Twitter</strong></p><p>1. 在給定 Twitter 用戶數據的情況下，你該如何衡量參與度？</p><p><strong>Uber</strong></p><p>1. 時間序列預測技術有什麼不同？</p><p>2. 解釋原理組件分析（Principle Component Analysis，PCA）和 PCA 使用的方程。</p><p>3. 如何解決多重共線性（Multicollinearity）？</p><p>4.（對分析師）請寫一個方程，優化我們在 Twitter 和 Facebook 上的廣告費用支出。</p><p><strong>Facebook</strong></p><p>1. 在一副牌中抽取兩張，出現同一花色的概率是多少？</p><p><strong>IBM</strong></p><p>1. 什麼是 p-value 和置信區間？</p><p><strong>Capital One</strong></p><p>1.（對數據分析師）如果你有 70 個紅色彈珠，綠色和紅色彈珠的比例是 2 比 7，有多少綠色彈珠？</p><p>2. 紐約市的通勤數據看起來應該遵從什麼分佈？</p><p>3. 一個骰子，在扔 6 次的情況下出現 1 個 6 的幾率，與扔 12 次的情況下出現至少兩個 6 的幾率，和扔 600 次出現至少 100 次 6 的幾率相比哪個大？</p><p><strong>Paypal</strong></p><p>1. 什麼是中心極限定理（Central Limit Theorem），如何證明它？它的應用方向是什麼？</p><h2><strong>編程和算法</strong></h2><p><strong>谷歌</strong></p><p>1.（對數據分析師）請寫一個程序可以判定二叉樹的高度。</p><p><strong>微軟</strong></p><p>1. 請創建一個函數檢查一個詞是否具有迴文結構。</p><p><strong>Twitter</strong></p><p>1. 請構建一個冪集（power set）。</p><p>2. 請問如何在一個巨大的數據集中找到中值？</p><p><strong>Uber</strong></p><p>1.（對數據工程師）編寫一個函數用來計算給定數字的平方根（2 個小數點精度）。隨後：避免冗餘計算，現在使用緩存機制優化你的功能。</p><p><strong>Facebook</strong></p><p>1. 假設給定兩個二進制字符串，寫一個函數將它們添加在一起，而不使用任何內置的字符串到 int 轉換或解析工具。例如：如果給函數二進制字符串 100 和 111，它應該返回 1011。你的解決方案的空間和時間複雜性如何？</p><p>2. 編寫一個函數，它接受兩個已排序的列表，併在排序列表中返回它們的並集。</p><p><strong>領英</strong></p><p>1.（對數據工程師）請編寫一些代碼來確定字符串中的左右括號是否是平衡的？</p><p>2. 如何找到二叉搜索樹中第二大的元素？</p><p>3. 請編寫一個函數，它接受兩個排序的向量，並返回一個排序的向量。</p><p>4. 如果你有一個輸入的數字流，如何在運行過程中找到最頻繁出現的數字？</p><p>5. 編寫一個函數，將一個數字增加到另一個數字，就像 pow（）函數一樣。</p><p>6. 將大字符串拆分成有效字段並將它們存儲在 dictionary 中。如果字符串不能拆分，返回 false。你的解決方案的複雜性如何？</p><p><strong>Captial One</strong></p><p>1.（對數據工程師）如何「拆散」兩個數列（就像 SQL 中的 JOIN 反過來）？</p><p>2. 請創建一個用於添加的函數，數字表示為兩個鏈表。</p><p>3. 請創建一個計算矩陣的函數。</p><p>4. 如何使用 Python 讀取一個非常大的製表符分隔的數字文件，來計算每個數字出現的頻率？</p><p><strong>Paypal</strong></p><p>1. 請編寫一個函數，讓它能在 O（n）的時間內取一個句子並逆向打印出來。</p><p>2. 請編寫一個函數，從一個數組中拾取，將它們分成兩個可能的數組，然後打印兩個數組之間的最大差值（在 O(n) 時間內）。</p><p>3. 請編寫一個執行合併排序的程序。</p><h2><strong>SQL 問題</strong></h2><p><strong>微軟</strong></p><p>1.（對數據分析師）定義和解釋聚簇索引和非聚簇索引之間的差異。</p><p>2.（對數據分析師）返回表的行計數有哪些不同的方法？</p><p><strong>Facebook</strong></p><p>1.（對數據工程師）如果給定一個原始數據表，如何使用 SQL 執行 ETL（提取，轉換，加載）以獲取所需格式的數據？</p><p>2. 如何編寫 SQL 查詢來計算涉及兩個連接的某個屬性的頻率表？如果你想要 ORDER BY 或 GROUP BY 一些屬性，你需要做什麼變化？你該怎麼解釋 NULL？</p><p><strong>領英</strong></p><p>1.（對數據工程師）如何改進 ETL（提取，轉換，加載）的吞吐量？</p><h2><strong>智力游戲</strong></h2><p><strong>谷歌</strong></p><p>1. 假設你有 10 包彈球，每包裡面都是 10 個彈球。如果其中一包的重量和其他的不同，但你只能進行一次稱重，你該用什麼辦法？</p><p><strong>Facebook</strong></p><p>1. 你打算坐飛機去西雅圖，想知道是不是需要帶傘，於是你分別打電話給三位在西雅圖的朋友。每個朋友都有 2/3 的幾率說真話，1/3 的幾率在騙你。如果他們都說「會下雨」，西雅圖下雨的概率是多少？</p><p>2. 假如在一個等邊三角形的三個角上都有一隻螞蟻，每隻隨機選擇方向然後直走一直到另一個邊緣，三隻螞蟻互相不交匯的幾率是多少？如果有 n 只螞蟻在 n 角形中，概率又是多少？</p><p>3. 在 100! 的結果里有多少個零？</p><p><strong>Uber</strong></p><p>1. 想象一下你在一家醫院工作。患者來就診的頻率符合泊松分佈，而醫生照顧患者的頻率符合均勻分佈。請寫一個函數或一段代碼來輸出患者的平均等待時間和醫生在某日的參與度。</p><p><strong>領英</strong></p><p>1. 你正在攀爬一個 n 階的樓梯，你可以採取任何數量的 k 個步驟。你到達樓梯頂部有多少不同的方式？（這是樓梯問題的修改版）</p><p>原文地址：http://www.learndatasci.com/data-science-interview-questions/</p><p><strong>本文由微信公眾號【機器之心】翻譯。</strong></p><p>End.</p><p>轉載請註明來自36大數據（36dsj.com)：<a href=\"http://www.36dsj.com\">36大數據</a> » <a href=\"http://www.36dsj.com/archives/78379\">谷歌微軟等科技巨頭數據科學面試107道真題：你能答出多少？</a></p> </article>', '來自 Glassdoor 的最新數據可以告訴我們各大科技公司最近在招聘面試時最喜歡向候選人提什麼問題。首先有一個令人惋惜的結論：根據統計，幾乎所有的公司都有著自己的不同風格。由於 Glassdoor 允許匿名提交內容，很多樂於分享的應聘者向大家提供了 Facebook、谷歌、微軟等大公司的面試題。我們把其中的一部分列出以供大家參考。', '2017-04-27', 'code', None, None, 'http://www.36dsj.com/archives/78379', 1, None)\n",
      "(3, 'python中理解字符串和編碼為什麼這麼難 | BIN 大數據', 'vivian', '<article class=\"article-content\"><p><img alt=\"大數據\" class=\"36img\" src=\"../static/pic/code/3_1.jpg\"/></p><p>在學習python2的時候,字符串和編碼可以說是最讓人困惑的知識點,假如知其然而不知其所以然,則在後續的寫代碼和學習過程中會讓人很痛苦,甚至會放棄,而對比PHP語言來說,即使完全不瞭解編碼等知識,也可以寫出代碼,這是幸事,但反過來說太透明會讓你失去很多能力.</p><p>python2字符串和編碼難理解的原因在於,一方面很多書籍很少說這方面的知識,另外一方面是python設計導致的,編碼問題和文件編碼,系統環境,IO操作等都有關係,混雜在一塊很讓人頭疼.</p><p>網絡上也有很多中文資料去說明,但是在學習的時候只能借鑒,原因在於寫的人理解的也是比較片面,很容易誤導人,所以在學習過程中一定要去實踐,要仔細琢磨.</p><p>自己綜合學習了下,以自己的方式寫了篇博客,能力有限,希望不要誤導人.</p><h3><strong>編碼</strong></h3><p>對於編碼個人覺得理解概念即可,具體的轉換規則,存儲規則可以不用太仔細瞭解,這類似於進制,知道概念即可,不強制掌握進制轉換的方法.</p><p>講編碼的文章很多,掌握以下概念即可.</p><p>世界上任何一個字符都可以用一個Unicode編碼來表示,一旦字符的Unicode編碼確定下來後，就不會再改變了,但是unicode存在二個局限性,第一一個Unicode字符在網絡上傳輸或者最終存儲起來的時候,並不見得每個字符都需要兩個字節,所以可能會造成空間浪費,第二一個Unicode字符保存到計算機裡面時就是一串01數字,那麼計算機怎麼知道一個2字節的Unicode字符是表示一個2字節的字符呢,還是表示兩個1字節的字符呢.</p><p>Unicode只是規定如何編碼,並沒有規定如何傳輸、保存這個編碼.</p><p>例如“漢”字的Unicode編碼是6C49,可以用4個ascii數字來傳輸、保存這個編碼,也可以用utf-8編碼的3個連續的字節E6 B1 89來表示它,關鍵在於通信雙方都要認可.</p><p>因此Unicode編碼有不同的實現方式,比如：UTF-8、UTF-16等等</p><h3><strong>python下的編碼</strong></h3><p>python2對於編碼理解困難,很大一部分原因在於系統有很多編碼,這裡說明下</p><pre class=\"prettyprint hljs css\"><span class=\"hljs-selector-id\">#windows</span>環境和<span class=\"hljs-selector-tag\">linux</span>環境下的區別<br><span class=\"hljs-selector-tag\">sys</span><span class=\"hljs-selector-class\">.getdefaultencoding</span>()<br><span class=\"hljs-selector-tag\">sys</span><span class=\"hljs-selector-class\">.getfilesystemencoding</span>()<br><span class=\"hljs-selector-tag\">locale</span><span class=\"hljs-selector-class\">.getdefaultlocale</span>()<br><span class=\"hljs-selector-tag\">locale</span><span class=\"hljs-selector-class\">.getpreferredencoding</span>()<br><span class=\"hljs-selector-tag\">sys</span><span class=\"hljs-selector-class\">.stdout</span><span class=\"hljs-selector-class\">.encoding</span>()</pre><ul><li><code>sys.getdefaultencoding()</code> 不管在何種環境下返回都是ascii,所以默認情況下轉碼解碼默認都是ascii</li><li>對於str類型, <code>locale.getdefaultlocale()</code> 決定了具體的編碼格式.具體見下麵說明</li><li><code>sys.stdout.encoding</code> 表示輸出使用的編碼,同樣的文件編碼,同樣的代碼,不同的系統環境輸出是有差異的</li></ul><p>最佳實踐</p><p>文件本身的編碼和文件頭編碼( <code># coding=utf-8</code> )保持一致</p><h3><strong>Python2中str和unicode對象</strong></h3><p>首先聲明下,自己運行的代碼在windows和linux環境各有一份示例,且通過python交互式解析器來說明.</p><p>python解析器不用用戶定義編碼頭,所以內部處理依賴於 <code>locale</code> 環境.</p><p>在windows機器運行</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; import locale<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; locale.getdefaultlocale()<br>(<span class=\"hljs-string\">\\'zh_CN\\'</span>, <span class=\"hljs-string\">\\'cp936\\'</span>)</pre><p>在linux機器運行</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; import locale<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; locale.getdefaultlocale()<br>(<span class=\"hljs-string\">\\'en_US\\'</span>, <span class=\"hljs-string\">\\'UTF-8\\'</span>)</pre><p>在python中和字符串相關的數據類型,分別是str、unicode兩種,他們都是basestring的子類.</p><h4><strong>在python代碼中定義str,unicode類型,解析器是如何解析的呢</strong></h4><ul><li>讀出文件內容</li><li>將內容根據 <strong>文件編碼</strong> 解碼成為unicode</li><li>解析unicode字符串,假如定義是 <code>u</code> 開頭,創建一個unicode對象</li><li>解析str字符串,將會從unicode按照文件編碼再編碼成為str對象</li></ul><h4><strong>通過代碼看看字符串在內部是如何存儲的</strong></h4><p>str類型</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-comment\">#windows</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a=<span class=\"hljs-string\">\"哈哈\"</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; type(a)<br>&lt;type <span class=\"hljs-string\">\\'str\\'</span>&gt;<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a<br><span class=\"hljs-string\">\\'xb9xfexb9xfe\\'</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; len(a)<br><span class=\"hljs-number\">4</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a[<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-string\">\\'xfe\\'</span><br><br><span class=\"hljs-comment\">#linux</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a = <span class=\"hljs-string\">\\'哈哈\\'</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; type(a)<br>&lt;type <span class=\"hljs-string\">\\'str\\'</span>&gt;<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a<br><span class=\"hljs-string\">\\'xe5x93x88xe5x93x88\\'</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; len(a)<br><span class=\"hljs-number\">6</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; a[<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-string\">\\'x93\\'</span></pre><p>str存儲的是已經編碼後的字節序列,輸出時看到每個字節用16進製表示,以x開頭,</p><p>linux環境下每個漢字會占用3個字節的長度,windows環境下每個漢字會占用2個字節的長度</p><p>unicode類型</p><pre class=\"prettyprint hljs python\"><span class=\"hljs-comment\">#linux和windows環境一樣</span><br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>a=<span class=\"hljs-string\">u\\'哈哈\\'</span><br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>type(a)<br>&lt;type <span class=\"hljs-string\">\\'unicode\\'</span>&gt;<br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>a<br><span class=\"hljs-string\">u\\'u54c8u54c8\\'</span><br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>len(a)<br><span class=\"hljs-number\">2</span><br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>a[<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-string\">u\\'u54c8\\'</span></pre><p>unicode是 <code>\"字符\"</code> 串，存儲的是編碼前的字符,輸出是看到字符以u開頭,每個漢字占用一個長度</p><p>通過上述可以看出:</p><ul><li>定義unicode和系統環境沒有聯繫,存儲的是以u開頭的unicode字符集</li><li>str類似於字符數組,str類型定義內部存儲則和系統環境有關係,假如系統環境是utf-8則存儲utf-8規則的字符數組,假如系統環境是cp936則存儲cp936規則的字符數組.</li><li>str類型不要使用len這樣的函數,因為截取出來可能就是所謂的亂碼了.</li></ul><h3><strong>python2中str和unicode如何轉換</strong></h3><p>既然同時存在str和unicode類型,則就涉及到二者的轉換了.</p><p>先說基本概念</p><ul><li>str = unicode.encode(字符編碼),從unicode轉換成指定編碼的str對象</li><li>unicode = str.decode(字符編碼),特指從指定編碼的str對象轉換為unicode對象</li></ul><p>註意:</p><ul><li>str轉換為unicode的時候,必須知道原有字符串編碼是什麼類型的,假如指定錯誤則會報錯</li><li>str從一種編碼轉換為另外一種編碼的時候,必須先轉換為unicode,再轉換成指定編碼的str類型</li></ul><p>一般情況下,不應該同時定義str和unicode類型,儘量使用unicode類型,假如都統一使用unicode類型,那為什麼還要出現str類型呢,在python2中,一般在I/O操作的時候才會有編碼轉換,這在後面描述.</p><h3><strong>print字符串發生了什麼</strong></h3><p>任何對象都默認包含內建方法 <strong>str</strong> ,在print的時候,該方法生效</p><p>假如print unicode對象,則根據默認編碼解碼為str對象.</p><p>假如print str對象,由於輸出就是str對象,默認不用做任何解碼.</p><p>看下麵的例子,註意這裡是通過python file.py的方式運行,在windows下運行是亂碼,而在linux下運行顯示正確,原因在於 <code>sys.stdout.encoding</code></p><pre class=\"hljs nginx\"><span class=\"hljs-comment\">#!/usr/bin/env python</span><br><span class=\"hljs-comment\">#coding=utf-8</span><br><span class=\"hljs-attribute\">a</span> = <span class=\"hljs-string\">\\'哈哈\\'</span><br>print a</pre><p><code>sys.stdout.encoding</code> 表示print輸出使用的編碼.</p><p>在linux環境下,由於輸出的編碼本來就是utf-8,所以能正確顯示</p><p>在windows環境下,str字符串存儲的是utf-8序列,顯示要求的卻是gbk,則出現亂碼,所以需要轉碼,修改如下:</p><pre class=\"prettyprint hljs nginx\"><span class=\"hljs-comment\">#!/usr/bin/env python</span><br><span class=\"hljs-comment\">#coding=utf-8</span><br><span class=\"hljs-attribute\">a</span> = <span class=\"hljs-string\">\\'哈哈\\'</span><br>print a.decode(<span class=\"hljs-string\">\\'utf-8\\'</span>).encode(<span class=\"hljs-string\">\\'gbk\\'</span>)  <span class=\"hljs-comment\">#在內部存儲gbk類型的str字符串</span></pre><p>而定義uinicode對象的時候,不會涉及任何的轉碼問題,print的時候,unicode對象能夠根據文件編碼自動轉換</p><p>以下代碼在任何環境下都能正常運行</p><pre class=\"hljs python\"><span class=\"hljs-comment\">#!/usr/bin/env python</span><br><span class=\"hljs-comment\">#coding=utf-8</span><br>a = <span class=\"hljs-string\">u\\'哈哈\\'</span><br><span class=\"hljs-keyword\">print</span> a</pre><h3><strong>IO操作發生了什麼</strong></h3><p>正因為有IO操作,str類型的對象可能才有存在的意義.或者說假如沒有可惡的str對象,則世界就太平了.</p><p>內置的open函數打開文件時,read方法讀取的是一個str,用你知道的編碼把它解碼成unicode</p><p>open函數打開文件之後的寫操作,則需要將需要寫入的字符串按照其編碼encode為一個str.</p><p>是不是很熟悉,print語句輸出和文件打開一樣都是str類型,盡可能處理的時候拋棄str,確保處理的對象是unicode,只在需要的時候才轉碼.</p><p>通過下麵的代碼就能明白繁瑣的轉碼和解碼操作</p><pre class=\"prettyprint hljs python\"><span class=\"hljs-comment\">#!/usr/bin/env python</span><br><span class=\"hljs-comment\">#coding=utf-8</span><br><br><span class=\"hljs-keyword\">import</span> os <br><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">filewrite</span><span class=\"hljs-params\">()</span>:</span> <br>    file1 = os.getcwd() + <span class=\"hljs-string\">\"1.txt\"</span><br>    file2 = os.getcwd() + <span class=\"hljs-string\">\"2.txt\"</span><br>    str= <span class=\"hljs-string\">u\\'我們是中國人\\'</span><br><br>    f = open(file1, <span class=\"hljs-string\">\"a\"</span>)<br>    f.write(str.encode(<span class=\"hljs-string\">\\'gbk\\'</span>))<br>    f.close()<br><br>    f2 = open(file2, <span class=\"hljs-string\">\"a\"</span>)<br>    f2.write(str.encode(<span class=\"hljs-string\">\\'utf-8\\'</span>))<br>    f2.close()<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fileread</span><span class=\"hljs-params\">()</span>:</span><br><br>    file1 = os.getcwd() + <span class=\"hljs-string\">\"1.txt\"</span><br>    file2 = os.getcwd() + <span class=\"hljs-string\">\"2.txt\"</span><br><br>    f= open(file1,<span class=\"hljs-string\">\"r\"</span>)<br>    data = f.read()<br>    print(data)<br><br>    f= open(file2,<span class=\"hljs-string\">\"r\"</span>)<br>    data = f.read()<br>    print(data.decode(<span class=\"hljs-string\">\\'utf-8\\'</span>))<br><br>filewrite()<br>fileread()</pre><p>IO操作使用codecs</p><p>codecs模塊也提供了一個open函數,可以直接指定好編碼打開一個文本文件,那讀取到的文件內容則直接是一個unicode字符串.對應的指定編碼後的寫入文件,則可以直接將unicode寫到文件中</p><pre class=\"prettyprint hljs python\"><span class=\"hljs-comment\">#!/usr/bin/env python</span><br><span class=\"hljs-comment\">#coding=utf-8</span><br><span class=\"hljs-keyword\">import</span> codecs<br><span class=\"hljs-keyword\">import</span> os <br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">codecswrite</span><span class=\"hljs-params\">()</span> :</span><br>    file3 = os.getcwd() + <span class=\"hljs-string\">\"3.txt\"</span><br>    str = <span class=\"hljs-string\">u\\'哈哈\\'</span><br>    f = codecs.open(file3,<span class=\"hljs-string\">\"w\"</span>,<span class=\"hljs-string\">\\'utf-8\\'</span>) <br>    f.write(str)<br>    f.close()<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">codecsread</span><span class=\"hljs-params\">()</span>:</span><br>    file3 = os.getcwd() + <span class=\"hljs-string\">\"3.txt\"</span><br>    f = codecs.open(file3,<span class=\"hljs-string\">\"r\"</span>,<span class=\"hljs-string\">\\'utf-8\\'</span>) <br>    data = f.read()<br>    <span class=\"hljs-keyword\">print</span> (data)<br><br>codecswrite()<br>codecsread()</pre><h3><strong>字符串拼接發生了什麼</strong></h3><p>unicode和str類型通過+拼接時,輸出結果是unicode類型,相當於先將str類型的字符串通過decode()方法解碼成unicode再拼接</p><pre class=\"prettyprint hljs awk\"><span class=\"hljs-comment\">#windows環境,python交互式運行</span><br>&gt;&gt;&gt;a=<span class=\"hljs-string\">\"中國\"</span><br>&gt;&gt;&gt;b=<span class=\"hljs-string\">u\"你好\"</span><br>&gt;&gt;&gt;a+b</pre><p>會出現 <code>UnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xd6 in position 0: ordinal not in range(128)</code> 錯誤,原因在於python自動將str類型的變量按照默認的編碼格式sys.getdefaultencoding()來解碼,默認編碼即ascii,而這個字符不在ascii的範圍內,就出現了錯誤,所以需要修改如下</p><pre class=\"prettyprint hljs python\"><span class=\"hljs-comment\">#windows環境,python交互式運行</span><br>&gt;&gt;&gt;a=<span class=\"hljs-string\">\"中國\"</span><br>&gt;&gt;&gt;b=<span class=\"hljs-string\">u\"你好\"</span><br><span class=\"hljs-meta\">&gt;&gt;&gt; </span>a.decode(<span class=\"hljs-string\">\\'gbk\\'</span>)+b<br><span class=\"hljs-string\">u\\'u4e2du56fdu4f60u597d\\'</span></pre><h3><strong>讓我們輕鬆下</strong></h3><p>這裡看下python中的字符串的處理方式,其實在學習的時候和PHP比較下更讓人有印象</p><h4><strong>單引號,雙引號,轉義</strong></h4><p>python中,字符串可以用單引號和雙引號括起來,沒有區別.</p><p>假如字符串用單引號括起來,則字符串中則不能有單引號,除非通過轉義去處理,同理雙引號也一樣</p><h4><strong>str和repr</strong></h4><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; <span class=\"hljs-string\">\"hello\"</span><br><span class=\"hljs-string\">\\'hello\\'</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print <span class=\"hljs-string\">\"hello\"</span><br>hello</pre><p>通過python打印的字符串會被雙引號括起來,這是因為python打印值的時候會保持該值在python代碼中的狀態.</p><p>而通過python語句則結果不一樣.</p><p>這裡就涉及到值被轉換為字符串的兩種機制:</p><p><code>str函數</code> :把值轉換為合理形式的字符串,以便人類能夠理解.</p><p><code>repr函數</code> :把值轉換為python能夠認識的值.</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print repr(<span class=\"hljs-string\">\"hello\"</span>)<br><span class=\"hljs-string\">\\'hello\\'</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print repr(<span class=\"hljs-number\">1000</span>L)  <br><span class=\"hljs-number\">1000</span>L<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print str(<span class=\"hljs-string\">\"hello\"</span>) <br>hello<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print str(<span class=\"hljs-number\">1000</span>L)  <br><span class=\"hljs-number\">1000</span></pre><h4><strong>input和raw_input</strong></h4><p>input假設輸入的是合法的python表達式,不然會報錯</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; name=input(<span class=\"hljs-string\">\"please:\"</span>)<br><span class=\"hljs-symbol\">please:</span>hello<br>Traceback (most recent call last):<br>  File <span class=\"hljs-string\">\"&lt;stdin&gt;\"</span>, line <span class=\"hljs-number\">1</span>, <span class=\"hljs-keyword\">in</span> &lt;<span class=\"hljs-class\"><span class=\"hljs-keyword\">module</span>&gt;</span><br>  File <span class=\"hljs-string\">\"&lt;string&gt;\"</span>, line <span class=\"hljs-number\">1</span>, <span class=\"hljs-keyword\">in</span> &lt;<span class=\"hljs-class\"><span class=\"hljs-keyword\">module</span>&gt;</span><br><span class=\"hljs-symbol\">NameError:</span> name <span class=\"hljs-string\">\\'hello\\'</span> is <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">defined</span></pre><p>應該變更為:</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; name=input(<span class=\"hljs-string\">\"please:\"</span>)<br><span class=\"hljs-symbol\">please:</span><span class=\"hljs-string\">\"hello\"</span><br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print name<br>hello</pre><p>而raw_input函數則將所有的輸入當作原始數據</p><pre class=\"prettyprint hljs ruby\"><span class=\"hljs-meta\">&gt;&gt;</span>&gt; name=raw_input(<span class=\"hljs-string\">\"please:\"</span>)<br><span class=\"hljs-symbol\">please:</span>hello<br><span class=\"hljs-meta\">&gt;&gt;</span>&gt; print name<br>hello</pre><p>長字符串</p><p>假如要寫多行的字符可以使用三個引號</p><pre class=\"hljs python\">str=<span class=\"hljs-string\">\\'\\'\\'hello<br>world str<br>\\'\\'\\'</span><br>print(str)</pre><p>引號之間的內容原本是什麼樣輸出也是什麼樣的,可以直接使用單雙引號,不用轉義</p><p>普通字符也可以跨行,只要一行之中最後一個字符是反斜線,那麼換行就轉義了</p><pre class=\"hljs rust\"><span class=\"hljs-keyword\">str</span>=<span class=\"hljs-symbol\">\\'hello</span><br>world\\'<br>print(<span class=\"hljs-keyword\">str</span>)</pre><p>原始字符串</p><p>原始字符串對於反斜線不會特殊對待</p><pre class=\"hljs python\">str=<span class=\"hljs-string\">r\\'hellonworld\\'</span><br>print(str)</pre><p><code>n</code> 字符在原始字符串裡面就不是換行了而是原始的n字符</p><p>End.</p><p>轉載請註明來自36大數據（36dsj.com)：<a href=\"http://www.36dsj.com\">36大數據</a> » <a href=\"http://www.36dsj.com/archives/80925\">python中理解字符串和編碼為什麼這麼難</a></p> </article>', '在學習python2的時候,字符串和編碼可以說是最讓人困惑的知識點,假如知其然而不知其所以然,則在後續的寫代碼和學習過程中會讓人很痛苦,甚至會放棄,而對比PHP語言來說,即使完全不瞭解編碼等知識,也可以寫出代碼,這是幸事,但反過來說太透明會讓你失去很多能力.', '2017-04-27', 'code', None, None, 'http://www.36dsj.com/archives/80925', 1, None)\n",
      "(4, '“今日頭條”怎麼計算：“網絡爬蟲+相似矩陣”技術運作流程 | BIN 大數據', 'vivian', '<article class=\"article-content\"><p><img alt=\"今日頭條\" class=\"36img\" src=\"../static/pic/code/4_1.jpg\"/></p><p>今日頭條這類資訊聚合平臺是基於數據挖掘技術，篩選和推薦新聞：“它為用戶推薦有價值的、個性化的信息，提供連接人與信息的新型服務，是國內移動互聯網領域成長最快的產品服務之一”。自從2012年3月創建以來，今日頭條至今已經累計激活用戶3.1億，日活躍用戶超過3000萬。</p><p>本文嘗試從技術層面分析今日頭條的傳播機制和相關原理。</p><h2><strong>網絡爬蟲：抓取新聞的基本技術</strong></h2><p>今日頭條是一個典型的數據新聞平臺，其新聞來源除了合作媒體之外，很大一部分來自於搜索引擎的網絡爬蟲。</p><p>網絡爬蟲是什麼？</p><p style=\"padding-left: 60px;\">STEP 1：從互聯網各個角落收集信息；</p><p style=\"padding-left: 60px;\">STEP 2：將其中的新聞類信息進行彙總；</p><p style=\"padding-left: 60px;\">STEP 3：彙總的信息經過基於機器學習的分類和排序，劃分出每一個時刻的熱點新聞。</p><p>今日頭條作為數據新聞平臺，與一般數據新聞的區別，在於提供一個媒介平臺，展示彙總的信息，而不是一條信息。</p><p>網絡爬蟲的工作機制是什麼？</p><p>網絡爬蟲的工作機制依賴於會聯網互聯網上的超鏈接網絡。</p><p>在互聯網上多數網頁，都有超鏈接存在。這些超鏈接將各個網頁鏈接起來構成了一個龐大的網絡，也就是超鏈接網絡。爬蟲作為一種網絡程序從一些網頁出發，保存網頁的內容，尋找網頁當中的超鏈接，然後訪問這些超鏈接，並重覆以上過程，這個過程可以不斷進行下去。如圖所示：</p><p><img alt=\"爬蟲\" class=\"36img\" src=\"../static/pic/code/4_2.jpg\"/></p><p>“今日頭條”怎麼計算：“網絡爬蟲+相似矩陣”技術運作流程</p><p style=\"padding-left: 60px;\">STEP 1：爬蟲從一個種子節點0開始爬取網頁內容，</p><p style=\"padding-left: 60px;\">STEP 2：抓取的同時發現兩個超鏈接，並爬取第一級節點，</p><p style=\"padding-left: 60px;\">STEP 3：從第一級節點開始又發現第二級節點，這個過程不斷進行下去。</p><p>這個過程當中有兩種策略：</p><p>1、只有窮盡一個層級的所有頁面才爬取下一個層級，這種策略叫做“廣度優先”；</p><p>2、發現一個超鏈接後，立刻就開始爬取這個網頁，並持續深入下去，這種過程叫做“深度優先”。</p><p>補充說明：</p><p>上圖是一個樹狀網絡，現實的網絡不是這麼簡單的，裡面充滿了“迴路”，即新發現的網頁里的超鏈接指向的是已經爬取的老節點。這個時候就需要甄別那些網頁已經被成功抓取。</p><p>舉個慄子——</p><p>以今日頭條為例說明一下網絡爬蟲在新聞抓取中的工作流程：</p><p>STEP 1：工作人員先要在後臺設置新聞來源的字典，比如“網易新聞”、“新浪新聞”、“鳳凰新聞”、“浙江新聞”等等，</p><p>STEP 2：通過這些字典，網絡爬蟲將會鎖定到這些網站的超鏈接，從中抓取新聞。</p><p>補充說明：</p><p><strong>如果這條新聞是在這些新聞平臺相關的博客當中的內容，而不是新聞平臺本身的新聞，網絡爬蟲就抓不到了。</strong></p><p>聚合媒體的概念並非如此簡單，除了匯聚來自不同媒體的內容之外，聚合媒體更重要的特征是對不同信息進行分類併排序，得到一個信息彙總界面（aggregator），這種信息彙總往往表現為某種排行榜。這種排行榜在傳播機制上滿足網絡科學中所說的“優先鏈接機制”，即用戶的註意力更傾向於投向那些排名靠前的信息，這個過程可以被經典的傳播學發現：“樂隊花車效應”。這個發現起源於美國的選舉過程。候選人會站在樂隊花車上拉選票，贊同者會站到他的車上。研究發現，人們傾向於登上那些站滿了人的花車，而非那些只有很少人的花車。</p><h2><strong>推薦系統：個性化定製新聞的技術邏輯</strong></h2><p>個性化推薦在今日頭條當中發揮著重要作用。</p><p>今日頭條的用戶登錄非常人性化。作為一個後起之秀，今日頭條非常具有策略性地允許用戶使用微博、QQ等社交賬號登錄。這個過程實際上授權今日頭條挖掘個人社交網絡的基本信息。因而，便於獲取用戶的個性化信息，比如用戶的興趣、用戶屬性。越用越懂用戶，從而進行精準的閱讀內容推薦。</p><p>個性化推薦的基礎是構建推薦系統</p><p>推薦系統廣泛地應用於用戶沒有明確需求的場景。推薦系統就算法而言，可以分為：</p><p style=\"padding-left: 60px;\">社會化推薦（Social recommendation, 比如向朋友咨詢）；</p><p style=\"padding-left: 60px;\">基於內容的推薦（content-based filtering, 例如根據用戶觀看過的電影推薦其他與之相似的電影）；</p><p style=\"padding-left: 60px;\">基於協同過濾的推薦（collaborative filtering，例如查看排行榜，或者找到和自己興趣相似的用戶，看看他們最近看什麼電影）。</p><p>所以，可以用於構建推薦系統的信息也分為三類：<strong>好友、歷史興趣、註冊信息。</strong></p><p>推薦系統就是可以關聯用戶和物品的一種自動化工具。除了這些信息之外，時間、地點等信息均可加入到推薦系統的構建中來。現在，推薦系統已經廣泛地應用於新聞推薦、圖書推薦、音樂推薦、電影推薦、朋友推薦等領域，作為人工智能的一種形式，極大地方便了人們的生活和交往。</p><p><strong>推薦系統算法的基礎就是要構造相似性矩陣</strong></p><p>這種相似性矩陣可以是物與物的相似性，例如書籍之間的相似性、音樂之間的相似性。以下以基於物品的協同過濾算法（item-based collaborative filtering, ItemCF）為例。基於物品的協同過濾算法可以利用用戶的歷史行為，因而可以使得推薦結果具有很強解釋性。比如，可以給喜歡讀足球新聞的用戶推薦其它相似的新聞。基於物品的協同過濾算法主要分為兩步：</p><p>STEP 1：計算物品之間的相似度。</p><p>STEP 2: 根據用戶的歷史行為生成用戶的推薦列表。</p><p>假設有四個用戶：</p><p>用戶1在今日頭條的瀏覽記錄是[a、b、d]，</p><p>用戶2的瀏覽記錄是[b、c]，</p><p>用戶3的瀏覽記錄是[c、d]，</p><p>用戶4的瀏覽記錄是[b、c、d]；</p><p>可將這四個人的瀏覽行為表達為以下四個物品矩陣：</p><p><img alt=\"今日頭條\" class=\"36img\" src=\"../static/pic/code/4_3.jpg\"/></p><p>將個體用戶的物品矩陣相加，可以彙總為所有的新聞矩陣M，M[i][j]表示新聞i和新聞j被多個人同時閱讀的次數。如下所示：</p><p><img alt=\"今日頭條\" class=\"36img\" src=\"../static/pic/code/4_4.jpg\"/></p><p><strong>矩陣邏輯</strong></p><p>如果兩個新聞被多個人同時瀏覽，那麼可以說它們之間的相似度更高。</p><p>將以上矩陣歸一化就可以對矩陣進行操作並計算新聞之間的相似度，比如相關相似度或者餘弦相似度。</p><p>基於物品間的相似性度，如果有一個新用戶進入系統，並且他閱讀了新聞c，那麼ItemCF算法可以很快給出與新聞c相似度最高的新聞（b和d）,並推薦給這個新用戶。</p><p>在推薦過程中，推薦系統可以根據用戶的行為不斷優化相似矩陣，使得推薦越來越準確。</p><p>或者，如果用戶可以手動對每個新聞的興趣（如喜歡或討厭）標出，就可以使得推薦更準確。</p><p>本質上來說，上面兩個圖是熱點新聞、以及個人定製新聞的基礎原理。它分為兩步完成：</p><p>STEP 1：先找出新聞之間的熱點與相似度</p><p>STEP 2：將熱點與相似度高的新聞推送給用戶。</p><p>舉個慄子——</p><p>假設在抗戰勝利70周年當天，有4個人同時瀏覽今日頭條的新聞，</p><p>A是女讀者，她點擊了秋季糖水製作方法、育兒應註意的五個事項、閱兵式、新型武器等新聞，</p><p>B是中年上班族，他點擊了閱兵式、中國最新兵器譜等新聞，</p><p>C是一位年長者，他點擊了養生、閱兵式、新型武器等新聞，</p><p>D是一位剛畢業的男大學生，他點擊了英雄聯盟攻略、好萊塢旅行攻略、閱兵式、新型武器等新聞。</p><p>熱點和相似度的產生過程：</p><p>STEP 1：這四個人同時點擊閱兵式和新型武器，系統算法就會通過點擊和停留的時間計算出閱兵式和新型武器是當天的熱點。</p><p>STEP 2：閱兵式和新型武器同時被多人點擊，代表他們之間具有相似性。</p><p>STEP 3：當新進用戶點擊新聞時，今日頭條會以最快速度分析他點擊的內容，併在已經排查出的熱點新聞當中尋找他所感興趣的相關內容匹配給他，引導他閱讀熱點。</p><p>這一系列的行為都由計算機自動完成。</p><p><strong>機制的缺陷</strong></p><p>上面的例子說明瞭定製新聞以泛熱點新聞為基礎數據來完成的事實，這就出現一個問題，即當一個人關註的新聞不是熱點時，系統得不到相關的熱點，就會在該新聞當中尋找其他信息進行再匹配，這樣匹配出的新聞在現有信息的基礎上最大程度吻合了用戶的興趣，但未必會推送當天最熱點的新聞。要想達到這種長尾理論所設想的定製服務，關鍵是對新聞的細分。只有將不同主題細分成各種子主題，再細分下設內容，才能達到真正的私人定製。要做到這一點，實際已經脫離了機械，而在於人對於事物性質的認知與把握。正如法國社會學家福柯在《知識考古學》當中的觀點，分類，是一事物區別於其他事物的根本。而分類，歸根結底是人的主觀能動性的體現；當系統中累計的用戶行為越 多，這種分類越準確，自動化的私人定製也會越貼近用戶需求。</p><h2><strong>聚合媒體：一種國際新聞界的潮流</strong></h2><p>聚合媒體在國外的應用也非常廣闊。信息在聚合媒體的數據新聞平臺上的展現，可以是傳統的搜索引擎的平面化展現，也可以是可視化展現。後者如日本的新聞地圖網站（http://newsmap.jp）。日本的新聞地圖項目是基於谷歌新聞做的，它採用不同的顏色將新聞類別區分開來，如紅色代表“World”，黃色代表“National”，用戶可以通過勾選頁面底部的分類欄進行篩選，在頁面頂部可以按照國家和地區進行篩選。網站後臺算法依據相關新聞信息的數量、重要性、點擊量自動調整每個新聞所占面積的大小。</p><p>一個非常有意思的聚合新聞網站是GDELT。 GDELT項目（The GDELT Project，http://gdeltproject.org/）監測全球100多種語言實時的廣播、印刷和網絡新聞，識別新聞中的人、地、組織、數量、主題、來源、情緒、時間。基於此，GDELT推出了全球新聞情緒地圖，數據每一個小時更新一次。其中綠色表示快樂，黃色表示悲傷。數據密度反映了新聞的規模，見下圖：</p><p><img alt=\"今日頭條\" class=\"36img\" src=\"../static/pic/code/4_5.jpg\"/></p><p>另外一個很好的例子是社交新聞網站，主要以Digg、Reddit等。這種類型的網站允許用戶註冊、相互關註、提交新聞並對新聞進行打分。其中，得分高的新聞就會進入到流行新聞的頁面。在這個過程當中，各個用戶充當了新聞的把關人，而這種信息把關的方式被稱之為群體把關。</p><p>但是，群體把關的意義主要在於將新聞推到流行頁面（webpage ofpopular news）,也就是公眾面前。這個階段之後流行信息擴散更像是傳統媒體的新聞擴散方式。其實，這種基於用戶過濾的新聞聚合（news aggregation）存在非常普遍，例如新浪微博上的“熱門話題”、推特上的“趨勢性話題”（trend）等。根據筆者對Digg上新聞擴散的分析，這種新聞聚合對於信息擴散的影響更大，對於那些傳播廣泛的Digg新聞，70%以上的信息接觸是通過熱門新聞被Digg用戶看到的。</p><h2><strong>主流新聞觀與人工智能</strong></h2><p><strong>從媒體把關到群體把關是一個進步，從群體把關到計算機或算法把關則隱藏著危險。</strong></p><p>過去由編輯所承擔的內容揀選的工作，現在交給了計算機來處理。其信息把關機制發生了根本的變化。在這個過程當中，受到最大影響的是傳統的新聞生產邏輯。傳統的新聞觀重視公眾利益，報道具有長遠影響的事件並提供見解。將這些工作交給機器和算法將帶來前所未有的挑戰：</p><p>首先，算法根據使用者所表現出來的“興趣”進行分類和推薦信息，往往容易給用戶推薦一些低質量但用戶短期內喜歡的信息。</p><p>其次，不斷地接觸低質量的信息使得個體的新聞素養降低。過於依賴機器幫助我們進行信息把關，容易導致視角越來越局限，不再關註社會整體利益，容易走向犬儒主義。</p><p>再次，主流的新聞操作手法保障了新聞從業者面對政治、軍事和社會力量時的獨立和從容。而推薦算法從信息和用戶出發，對於國家和社會整體的關註不夠，這種新聞推送機制的偏向容易帶來攻訐。</p><h2><strong>未來新聞業走向人機結合時代</strong></h2><p>從未來新聞的視角來思考新聞行業的轉型更加使得我們意識到回歸新聞本質的重要性。</p><p>未來的新聞行業不僅僅是提供有限的案例訪談，而是系統地獲取、積累並分析數據，並挖掘隱含其中的信息。在註意力經濟的時代，向用戶提供這種專業化的信息、專 業化的評論才是媒體的責任。目前迅速崛起的數據新聞正在走向這個方向，只不過在現階段更註重可視化表達。聚合媒體將信息過濾自動化，體現了未來新聞的特 點。基於個性化的推薦，聚合媒體將人工智能的新聞整合功能進一步帶進我們的生活，提供了很多便利。但是，不應該忽略的是，要警惕太依賴機器和算法所潛藏的 危險：算法或計算機把關有損新聞價值取向。</p><p>未來的新聞業，走向人機結合的時代。</p><p>作者：王成軍（南京大學新聞傳播學院助理研究員，奧美數據科學實驗室主任，計算傳播學中心研究）</p><p>本文摘編自《傳媒評論》2015年10月刊</p><p>End.</p><p>轉載請註明來自36大數據（36dsj.com)：<a href=\"http://www.36dsj.com\">36大數據</a> » <a href=\"http://www.36dsj.com/archives/35286\">“今日頭條”怎麼計算：“網絡爬蟲+相似矩陣”技術運作流程</a></p> </article>', '今日頭條這類資訊聚合平臺是基於數據挖掘技術，篩選和推薦新聞：“它為用戶推薦有價值的、個性化的信息，提供連接人與信息的新型服務，是國內移動互聯網領域成長最快的產品服務之一”。自從2012年3月創建以來，今日頭條至今已經累計激活用戶3.1億，日活躍用戶超過3000萬。', '2017-04-27', 'code', None, None, 'http://www.36dsj.com/archives/35286', 5, None)\n",
      "(5, '微信公眾號爬蟲 | BIN 大數據', 'vivian', '<article class=\"article-content\"><p><img alt=\"手機\" class=\"36img\" src=\"../static/pic/code/5_1.jpg\"/></p><h3><strong>前言</strong></h3><p>無論是新方案還是舊方案, 獲取公眾號文章列表, 獲取閱讀點贊, 獲取評論等接口可以通過抓包來獲取</p><p>以上接口都是需要授權的, 授權參數主要有一下幾個：</p><ul><li><strong>uin : 用戶對於公眾號的唯一ID, 本來是一個數字, 傳的是base64之後的結果</strong></li><li><strong>key : 與公眾號和uin綁定, 過期時間大概是半小時</strong></li><li><strong>pass_ticket: 另外一個驗證碼, 與uin進行綁定</strong></li><li><strong>req_id: 在文章里HTML里, 每次請求會不一樣, 用來構成獲取閱讀點贊接口的RequestBody, 一次有效</strong></li><li><strong>獲取閱讀點贊接口有頻率限制, 測試的結果是一個微信號5分鐘可以查看30篇文章的閱讀點贊</strong></li></ul><h3><strong>舊方案</strong></h3><p>在2015年的時候微信網頁版限制還是沒那麼嚴格的, 當時採用的主要思路是使用微信網頁版, 然後用requests去模擬登陸一下,</p><p>然後不停的去訪問類似下麵的接口爬取信息:\\xa0&gt;</p><p><img alt=\"接口\" class=\"36img\" src=\"../static/pic/code/5_2.jpg\"/></p><p>當時為了能讓爬蟲多個實例跑, 用了一下 Celery 框架(現在想簡直智障, 多個實例跑直接把程序啟動N次就行了啊。。摔), 由於是模擬登陸, 所以又寫了一套複雜的東西去生成二維碼, 然後獲取登陸URL, 具體的模擬登陸原理參考這個 wechat-deleted-friends, 另外相關的Celery Task里寫的邏輯太複雜了, 一個Task里就帶上了 requests斷線重連機制, 模擬登陸機制, 解析列表, 解析文章等, 另外由於是web版微信有一套蠻複雜的sync機制, 有時候直接掉線需要再次的去手動登陸, 很是麻煩。</p><p>之後web版微信已經無法的獲取Key了(2016年開始), 此方案就廢棄了。。</p><h3><strong>新方案</strong></h3><p>經leader提醒, 改了一下架構, 其中項目的整體結構如下:</p><p><center><img alt=\"架構圖\" class=\"36img\" src=\"../static/pic/code/5_3.jpg\"/></center></p><p style=\"text-align: center;\">微信爬蟲架構圖</p><ul><li><strong>Seeds 是一個producer, 在此處指通過某種方式獲取 uin, key, pass_ticket 信息, 思路類似中間人攻擊+解析squid日誌</strong></li><li><strong>Consumer C1從Q1隊列中取出seeds後爬取某個公眾號的文章列表, 解析後將文章Meta信息放入隊列Q2</strong></li><li><strong>Consumer C2獲取文章原信息後就可以直接做入庫&amp;爬取操作了</strong></li><li><strong>之後可以繼續加隊列然後去實現爬取文章閱讀點贊的相關數據了, 由於有頻率限制。一個微信號一天只能最多獲取8000篇文章的閱讀點贊信息</strong></li><li><strong>拋棄了Celery和其默認選用的RabbitMQ隊列, 這種東西實在太重了。。改用beanstalkd做消息隊列</strong></li><li><strong>目前的效果是單微信號每日更新4w左右的公眾號文章, 如果想繼續增加數量可以通過加機器來擴展</strong></li></ul><p>via:疊搭寶箱</p><p>End.</p><p>\\xa0</p><p>轉載請註明來自36大數據（36dsj.com)：<a href=\"http://www.36dsj.com\">36大數據</a> » <a href=\"http://www.36dsj.com/archives/56580\">微信公眾號爬蟲</a></p> </article>', '無論是新方案還是舊方案, 獲取公眾號文章列表, 獲取閱讀點贊, 獲取評論等接口可以通過抓包來獲取', '2017-04-27', 'code', None, None, 'http://www.36dsj.com/archives/56580', 3, None)\n"
     ]
    }
   ],
   "source": [
    "result = engine.execute(\"SELECT * from article;\")\n",
    "for a in result:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
