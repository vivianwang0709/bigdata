{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 1.063492 sec\n",
      "It cost 3.409766 sec\n"
     ]
    }
   ],
   "source": [
    "import requests,re,json\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import time\n",
    "\n",
    "#下載圖片\n",
    "from io import StringIO,BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "async def download_img(pid,url,path,pcount,article_type):\n",
    "    image_name = pid+'_'+str(pcount)+'.jpg'\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(url) as resp:\n",
    "            i = await resp.read()\n",
    "            with open(path+'/'+image_name,\"wb\") as f :\n",
    "                f.write(i)\n",
    "\n",
    "\n",
    "def download_img_1(pid,url,path,pcount,article_type):\n",
    "    image_name = pid+'_'+str(pcount)+'.jpg'\n",
    "    i = requests.get(url)\n",
    "    with open(path+'/'+image_name,\"wb\") as f :\n",
    "        f.write(i.content)\n",
    "\n",
    "\n",
    "path = '../test'\n",
    "page_url_base = 'http://bigdatainsight.herokuapp.com/static/pic/code/4_'\n",
    "page_urls = [[i,page_url_base+str(i)+'.jpg'] for i in range(1,6)]\n",
    "\n",
    "\n",
    "tStart = time.time()#計時開始\n",
    "tasks = [asyncio.ensure_future(download_img('10',url[1],path,url[0],'news')) for url in page_urls]\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(asyncio.wait(tasks))\n",
    "tEnd = time.time()#計時結束\n",
    "print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位\n",
    "\n",
    "\n",
    "tStart = time.time()#計時開始\n",
    "for url in page_urls:\n",
    "    download_img_1('11',url[1],path,url[0],'news')\n",
    "tEnd = time.time()#計時結束\n",
    "print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests,re,json\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import time\n",
    "\n",
    "\n",
    "# 獲取文章內容\n",
    "def get_html(url):\n",
    "    s = requests.session()\n",
    "    headers = {\n",
    "        \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\"\n",
    "        ,\"Accept-Encoding\":\"gzip, deflate, sdch\"\n",
    "        ,\"Accept-Language\":\"zh-CN,zh;q=0.8,en;q=0.6,la;q=0.4\"\n",
    "        ,\"Cache-Control\":\"no-cache\"\n",
    "        ,\"Connection\":\"keep-alive\"\n",
    "        ,\"Cookie\":\"Hm_lvt_46db1c7ab0c594c8219d3a3d68e66ff8=1488466544; Hm_lpvt_46db1c7ab0c594c8219d3a3d68e66ff8=1490158290\"\n",
    "        ,\"Host\":\"www.36dsj.com\"\n",
    "        ,\"Pragma\":\"no-cache\"\n",
    "        ,\"Referer\":\"http://www.36dsj.com/?s=spark\"\n",
    "        ,\"Upgrade-Insecure-Requests\":\"1\"\n",
    "        ,\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "   \n",
    "    #發送數據請求\n",
    "    r = s.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "\n",
    "#下載圖片\n",
    "from io import StringIO,BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "async def download_img(pid,url,path,pcount,article_type):\n",
    "    image_name = pid+'_'+str(pcount)+'.jpg'\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(url) as resp:\n",
    "            i = await resp.read()\n",
    "            with open(path+'/'+image_name,\"wb\") as f :\n",
    "                f.write(i)\n",
    "\n",
    "\n",
    "def get_info(pid,url,path,article_type):\n",
    "    soup = get_html(url)\n",
    "\n",
    "\n",
    "    # make content\n",
    "    pcount = 0\n",
    "    page_urls=[]\n",
    "    for a_tag in soup.article.find_all('img'):\n",
    "        pcount = pcount + 1\n",
    "        url = [pcount,a_tag['src']]\n",
    "        page_urls.append(url)\n",
    "        a_tag['src'] = \"../static/pic/\"+pid+\"_\"+str(pcount)+\".jpg\"\n",
    "        a_tag['class'] = \"36img\"\n",
    "        del a_tag['width'],a_tag['height'],a_tag['sizes'],a_tag['srcset']\n",
    "    \n",
    "    tasks = [asyncio.ensure_future(download_img(pid,url[1],path,url[0],article_type)) for url in page_urls]\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(asyncio.wait(tasks))\n",
    "\n",
    "path = '../test'\n",
    "get_info('7','http://www.36dsj.com/archives/17187',path,'code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests,re,json,time\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.session()\n",
    "url='http://www.36dsj.com/archives/tag/spark/page/1'\n",
    "r = s.get(url)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in soup.find_all('div',class='excerpt'):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
